# ðŸ§§Red Packet System (Built with Golang, MySQL, Redis, Kafka)

## Overview
This is a high-performance red packet system built with Golang, MySQL, Redis Cluster, and Kafka. It demonstrates:
- High-concurrency red packet grabbing.
- Distributed transaction logging via Kafka (Producer/Consumer).
- Master-Slave Replication in MySQL, using dbresolver for read/write splitting.
- Redis caching, Bloom Filter for anti-penetration, RedLock for distributed locking, and Lua scripts for atomic stock decrement.
- Robust architecture to handle million-level concurrency, leveraging Docker + Docker Compose for container orchestration.

---
## ðŸ— Project Structure
```
red-packet-system/
â”œâ”€â”€ cmd/                    # Entry points for different services
â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â””â”€â”€ worker.go        # Kafka consumer worker
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â””â”€â”€ server.go        # API server main entry point
â”‚
â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ config.go            # Loads environment variables and system configurations (singleton)
â”‚
â”œâ”€â”€ db/                      # Database-related logic
â”‚   â”œâ”€â”€ migrations/          # SQL migration scripts
â”‚   â”‚   â”œâ”€â”€ 000001_red_packets.up.sql      # Red packet table
â”‚   â”‚   â”œâ”€â”€ 000002_red_packet_logs.up.sql  # Red packet transaction logs
â”‚   â”‚   â”œâ”€â”€ 000003_users.up.sql            # Users table
â”‚   â”œâ”€â”€ mysql.go             # GORM + dbresolver for read/write splitting
â”‚   â”œâ”€â”€ seed.go              # Database seed data
â”‚
â”œâ”€â”€ kafka/                   # Kafka producer and consumer
â”‚   â”œâ”€â”€ consumer.go          # Kafka consumer logic
â”‚   â”œâ”€â”€ producer.go          # Kafka producer logic
â”‚   â”œâ”€â”€ utils.go             # Helper functions for retries and error handling
â”‚
â”œâ”€â”€ model/                   # Data models (GORM-based)
â”‚   â”œâ”€â”€ red_packet.go        # RedPacket struct and ORM mappings
â”‚   â”œâ”€â”€ red_packet_log.go    # RedPacketLog struct for transaction logs
â”‚   â”œâ”€â”€ user.go              # User struct
â”‚
â”œâ”€â”€ pkg/                     # Utility libraries
â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â”œâ”€â”€ logger.go        # Logger singleton for structured logging  (singleton)
â”‚
â”œâ”€â”€ redisclient/             # Redis cluster and Redlock-based distributed locks
â”‚   â”œâ”€â”€ redis.go             # Redis connection and operations
â”‚
â”œâ”€â”€ routes/                  # API routes and endpoint definitions
â”‚   â”œâ”€â”€ router.go            # Gin router setup
â”‚
â”œâ”€â”€ service/                 # Business logic and services
â”‚   â”œâ”€â”€ red_packet_service.go # Core logic for grabbing red packets
â”‚
â”œâ”€â”€ api/                     # API handlers
â”‚   â”œâ”€â”€ handler.go           # HTTP handlers for API endpoints
â”‚
â”œâ”€â”€ nginx/                   # Nginx configuration
â”‚   â”œâ”€â”€ nginx.conf           # Load balancing and reverse proxy settings
â”‚
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ Dockerfile               # Docker setup for Multi-stage build (Go -> minimal runtime)
â”œâ”€â”€ docker-compose.yml       # Docker Compose setup for microservices (MySQL, Redis Cluster, Kafka, etc.)
â”œâ”€â”€ go.mod                   # Go module dependencies
â”œâ”€â”€ go.sum                   # Go module checksums
â”œâ”€â”€ README.md                # Project documentation
```

---
## ðŸ“ˆ Million-Level Concurrency Architecture
```
+--------------------------------+
|  Users (APP / Frontend)        |
+--------------------------------+
            â†“
+-----------------------------------------------+
|  Nginx (Load Balancing / Rate Limit -- TODO)  |
+-----------------------------------------------+
            â†“
+--------------------------------+
|  API Server (Golang + Gin)     |
+--------------------------------+
            â†“
+-------------------------------------------------------+
| Redis Cluster (Lua Scripts & Bloom Filter & RedLock)  |
|  Kafka (Multi-Partition Consumers)                    |
|  MySQL (Master-Slave Read/Write Splitting)            |
+-------------------------------------------------------+
```

---
## ðŸ”‘ Key Techniques & Features

### **1. Redis Cluster**
- Lua Scripts for atomic stock decrement (prevents race conditions).
- RedLock (distributed lock) ensures a single user canâ€™t over-grab the same red packet concurrently.
- Bloom Filter to avoid cache penetration. If an ID isnâ€™t in the Bloom Filter, we skip querying MySQL.
- Randomized TTL to mitigate cache avalanche (spreading expiration times so keys donâ€™t all expire simultaneously).

### **2. MySQL Master-Slave Replication**
- Using GORMâ€™s dbresolver plugin for read/write splitting: writes go to the master; reads go to the slave to scale read traffic.
- Seed script to populate test data.
- Transactional updates for red packet counts, ensuring strong consistency in MySQL itself.

### **3. Kafka**
- Producer: sends transaction events (user + amount) to Kafka.
- Consumer: runs in a separate worker to update user balances asynchronously.
- retryWithBackoff logic ensures robust error handling and prevents repeated consumption.
- Leverages partitioning to distribute load among consumers in a group.

### **4. Singleton Patterns**
- Config (using sync.Once to load .env or environment variables).
- Logger (shared logger instance).
- DB connection (GORM).
- Redis client.
- Minimizes overhead and ensures consistent usage across the codebase.

### **5. Graceful Shutdown**
- Listens for signals like SIGTERM, gracefully stops the HTTP server, flushes logs, closes DB connections, and stops Kafka consumption.

### **6. Docker & Docker Compose**
- Multi-stage Go build: minimal final image with only the compiled binaries.
- docker-compose.yml orchestrates MySQL (master + slave), Redis cluster, Kafka + Zookeeper, and the application containers.
- Health checks for MySQL, Kafka, and the Go services.

---
## ðŸš€ Quick Start

### **1. Prerequisites**
Ensure you have the following installed on your machine:
- **Docker** & **Docker Compose**
- **Golang 1.22+**
- **MySQL 5.7**
- **Redis**
- **Kafka & Zookeeper**

### **2. Setup & Installation**
```
git clone https://github.com/your-repo/red-packet-system.git
cd red-packet-system
docker-compose up -d --build
```

### **3. Database Migration & fake data**
Run migrations:
```
docker exec -it server-api /app/migrate -path=db/migrations \
  -database "mysql://root:123456@tcp(mysql-master:3306)/red_packet_db" up
```

Seed data (inserts test users & red packets):
```
docker exec -it server-api /app/server-api --seed
```

### **4. Configure MySQL Slave**
```
docker-compose -f docker-compose.yml exec mysql-slave bash

# Inside container:
mysql -uroot -p123456

# Set up replication
CHANGE MASTER TO MASTER_HOST='mysql-master', MASTER_USER='root', MASTER_PASSWORD='123456', MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=4;

# Ativate
START SLAVE;

# Check States
SHOW SLAVE STATUS\G;
```

### **5. Redis Cluster Setup**
```
# Redis Setting
docker-compose -f docker-compose.yml exec redis-cluster-1 bash

# Inside container:
redis-cli --cluster create \
redis-cluster-1:6379 \
redis-cluster-2:6379 \
redis-cluster-3:6379 \
--cluster-replicas 0

# Check cluster info
redis-cli cluster info
redis-cli cluster nodes
```

### **6. kfaka Usage**
Consumer (manual check):
```
docker exec -it kafka bash -c "/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic red_packet_transactions --from-beginning"
```

Producer (for test messages):
```
docker exec -it kafka bash -c " /opt/kafka/bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic red_packet_transactions"

# Then type a test message:
> 1,1,43.75
```

### **7. API Endpoints**
Health Check:
```
curl -X GET "http://localhost:8080"

{"message":"Red Packet System is running!"}
```

Grab a Red Packet:
```
curl -X GET "http://localhost:8080/grab?user_id=1&red_packet_id=1"

{
  "message": "Red packet grabbed successfully",
  "amount": 5.67
}
```

### **8. Logs & Monitoring**
```
# API logs
docker logs -f server-api

# Kafka consumer logs
docker logs -f kafka-worker
```